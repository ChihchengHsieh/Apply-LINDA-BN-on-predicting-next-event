{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd00fab9f4e2480a02528c8c5e2c5eed9f6f178de25ad0614451a9194f538e2ccc5",
   "display_name": "Python 3.9.4 64-bit ('dl')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.Constants import Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "emb_dim: int  = 256\n",
    "batch_size = 16\n",
    "vocab_size = 40\n",
    "seq_len = 20\n",
    "lstm_hidden = 32\n",
    "lstm_layer=2 \n",
    "dropout = .8\n",
    "\n",
    "fake_data = torch.randint(0, 10, (batch_size, seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = BaselineLSTMModel(\n",
    "    vocab_size= vocab_size,\n",
    "    embedding_dim= emb_dim,\n",
    "    lstm_hidden=lstm_hidden,\n",
    "    dropout=dropout,\n",
    "    num_lstm_layers= lstm_layer,\n",
    "    paddingValue= 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 20, 40])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "baseline_model(fake_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 13087/13087 [00:14<00:00, 900.94it/s]\n",
      "/Users/jrhs/.pyenv/versions/dl/lib/python3.9/site-packages/pandas/core/frame.py:1549: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from Data.BPI2012Dataset import BPI2012Dataset\n",
    "bpi2012 = BPI2012Dataset('../Data/event_logs/BPI_Challenge_2012.xes')\n",
    "loader = DataLoader(bpi2012, batch_size=32, shuffle=True, collate_fn= bpi2012.collate_fn)\n",
    "baseline_model = BaselineLSTMModel(\n",
    "    vocab_size= bpi2012.vocab_size(),\n",
    "    embedding_dim= 64,\n",
    "    lstm_hidden= 32,\n",
    "    dropout= .8,\n",
    "    num_lstm_layers= 2,\n",
    "    paddingValue= bpi2012.vocab_to_index(Constants.PAD_VOCAB),\n",
    ")"
   ]
  },
  {
   "source": [],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseids, train, target, lengths = iter(loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "start (845) + length (1) exceeds dimension size (845).",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0defc490a306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/NextEventPrediction/OurApproach/Models/BaselineLSMTModel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, lengths)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# input (B, S)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ( B, S, F )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/dl/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    662\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    665\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    666\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: start (845) + length (1) exceeds dimension size (845)."
     ]
    }
   ],
   "source": [
    "baseline_model(train, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class BaselineLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int,  lstm_hidden: int, dropout: float, num_lstm_layers: int, paddingValue: int = 0):\n",
    "        super(BaselineLSTMModel, self).__init__()\n",
    "\n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim, paddingValue)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_hidden, batch_first=True,\n",
    "                            dropout=dropout, num_layers=num_lstm_layers)\n",
    "\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden, vocab_size),\n",
    "        )\n",
    "\n",
    "        # The trainable init h0 and c0 in LSTM.\n",
    "        self.h0 = nn.Parameter(torch.randn(num_lstm_layers, 1, lstm_hidden))\n",
    "        self.c0 = nn.Parameter(torch.randn(num_lstm_layers, 1, lstm_hidden))\n",
    "\n",
    "    def forward(self, input: torch.tensor, lengths: np.ndarray = None) -> torch.tensor:\n",
    "        '''\n",
    "        Input size: (B ,S)\n",
    "        Output size: (B, S, vocab_size)\n",
    "        '''\n",
    "        # input (B, S)\n",
    "        batch_size = input.size(0)\n",
    "        out = self.emb(input)  # ( B, S, F )\n",
    "        print(\"after emb\")\n",
    "\n",
    "        if not lengths is None:\n",
    "            print(\"the len of lengths: {}\".format(len(lengths)))\n",
    "            print(\"the max length: {}\", lengths.max())\n",
    "            print(\"current tensor size {}\". format(out.shape))\n",
    "            print('in length')\n",
    "            out = pack_padded_sequence(out, lengths=lengths, batch_first=True)\n",
    "            print('after pack')\n",
    "            out, _ = self.lstm(out, (self.h0.repeat(\n",
    "                1, batch_size, 1), self.c0.repeat(1, batch_size, 1)))  # ( B, S, F)\n",
    "            print('after lstm')\n",
    "\n",
    "            out, _ = pad_packed_sequence(out, batch_first=True)\n",
    "            print('after pad')\n",
    "\n",
    "        else:\n",
    "            out, _ = self.lstm(out, (self.h0.repeat(\n",
    "                1, batch_size, 1), self.c0.repeat(1, batch_size, 1)))  # ( B, S, F)\n",
    "\n",
    "        out = self.output_net(out)  # (B, S, vocab_size)\n",
    "        print(\"after outnet\")\n",
    "        return out\n",
    "\n",
    "    def argmax_prediction(self, input: torch.tensor, lengths: np.ndarray = None, onlyReturnFinalStep: bool = True) -> torch.tensor:\n",
    "        seq_size = input.size(1)\n",
    "        out = self.forward(input)  # (B, S, vocab_size)\n",
    "        print(\"after forward\")\n",
    "        out = F.softmax(out, dim=-1)  # (B, S, vocab_size)\n",
    "        print(\"after softmax\")\n",
    "        out = torch.argmax(out, dim=-1)  # (B, S)\n",
    "        if onlyReturnFinalStep:\n",
    "            final_index = torch.tensor([l - 1 for l in lengths])\n",
    "            final_out_mask = torch.gt(F.one_hot(final_index, seq_size), 0)\n",
    "            out =  out.masked_select(final_out_mask) # (B)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/jrhs/.pyenv/versions/dl/lib/python3.9/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "parsing log, completed traces :: 100%|██████████| 13087/13087 [00:15<00:00, 834.58it/s]\n",
      "/Users/jrhs/.pyenv/versions/dl/lib/python3.9/site-packages/pandas/core/frame.py:1549: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from Data.BPI2012Dataset import BPI2012Dataset\n",
    "bpi2012 = BPI2012Dataset('../Data/event_logs/BPI_Challenge_2012.xes')\n",
    "loader = DataLoader(bpi2012, batch_size=32, shuffle=True, collate_fn= bpi2012.collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.Constants import Constants\n",
    "\n",
    "baseline_model = BaselineLSTMModel(\n",
    "    vocab_size= bpi2012.vocab_size(),\n",
    "    embedding_dim= 64,\n",
    "    lstm_hidden= 32,\n",
    "    dropout= .8,\n",
    "    num_lstm_layers= 2,\n",
    "    paddingValue= bpi2012.vocab_to_index(Constants.PAD_VOCAB),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseids, train, target, lengths = iter(loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "after emb\nthe len of lengths: 32\nthe max length: {} 87\ncurrent tensor size torch.Size([32, 87, 64])\nin length\nafter pack\nafter lstm\nafter pad\nafter outnet\n"
     ]
    }
   ],
   "source": [
    "out = baseline_model(train, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([32, 87, 39])"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "after emb\nafter outnet\nafter forward\nafter softmax\n"
     ]
    }
   ],
   "source": [
    "prediction_out = baseline_model.argmax_prediction(train, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "type(train.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "len(prediction_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([32, 87])"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}